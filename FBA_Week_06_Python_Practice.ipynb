{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prajaktahz/Uni_Colab_Work/blob/main/FBA_Week_06_Python_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](http://www.cs.nott.ac.uk/~pszgss/teaching/nlab.png)\n",
        "# FBA Computing Session Week 6:\n",
        "\n",
        "**More Pandas**\n",
        "\n",
        "The aim of this tutorial is to cover additional methods available within Pandas that could be useful when preprocessing the data.\n",
        "\n",
        "We'll explore\n",
        "- how to deal with missing (NaN) values;\n",
        "- how encoding and decoding is performed;\n",
        "- how to group and aggregate the data; and\n",
        "- how to change format from wide to long and back.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fVH9lcVuyAXN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "MVnNObGsdX_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "fRR9HusXdjW8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step A1: How to deal with NaNs in NumPy?**"
      ],
      "metadata": {
        "id": "mBiBMSFCdLv-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "B2CU_LzuxrtD",
        "outputId": "30835611-117d-43cf-c0c3-2d5fce8aaa40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "a = [[1,2,np.NaN],[4,5,6]]\n",
        "#new_a =\n",
        "np.mean(a)\n",
        "# [[1,2,3],[4,5,6]]\n",
        "# [[1,2,np.NaN],[4,5,6]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Is there a method that can help?\n",
        "new_a = np.array(a)\n",
        "#new_a = new_a[np.logical_not(np.isnan(a))]\n",
        "#new_a\n",
        "new_data = new_a[np.isfinite(new_a)]\n",
        "new_data"
      ],
      "metadata": {
        "id": "xW9wHycGSf7T",
        "outputId": "246243b8-7df6-4188-a76a-ee4bd2a5f605",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 2., 4., 5., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step A2: NaNs in Pandas?**\n",
        "\n",
        "Let's create a sample DataFrame with missing values to work with."
      ],
      "metadata": {
        "id": "1oo3KrUxec5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'A': [1, 2, np.nan, 4, 5],\n",
        "    'B': [6, np.nan, 8, np.nan, 10],\n",
        "    'C': [11, 12, 13, 14, 15]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "MA-MMA2nerHr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step A3: Identifying Missing Values**\n",
        "\n",
        "To identify missing values in your DataFrame, you can use the `isna()` or `isnull()` function. It will return a DataFrame of the same shape, with Booleans: `True` where the values are missing (NaN) and `False` where values are not missing."
      ],
      "metadata": {
        "id": "Z-dX_Y5_e1Mq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "missing_values = df.isna()\n",
        "print(missing_values)"
      ],
      "metadata": {
        "id": "7daY7Nj3fG08",
        "outputId": "3275e3e0-423e-49db-bc9d-953af55008d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       A      B      C\n",
            "0  False  False  False\n",
            "1  False   True  False\n",
            "2   True  False  False\n",
            "3  False   True  False\n",
            "4  False  False  False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step A4: Counting Missing Values**\n",
        "\n",
        "To count the missing values in each column, you can use the `sum()` function on the DataFrame returned from `isna()`."
      ],
      "metadata": {
        "id": "QkGtCNU-fOuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "missing_count = df.isna().sum()\n",
        "print(missing_count)"
      ],
      "metadata": {
        "id": "Pnhq-PR-fZIq",
        "outputId": "d1336d8f-ec0a-4b6d-ec19-c263468ccb7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A    1\n",
            "B    2\n",
            "C    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step A5: Removing Rows with Missing Values**\n",
        "\n",
        "You can remove rows with missing values using the `dropna()` function.**bold text**"
      ],
      "metadata": {
        "id": "XdjDamgbfndF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "df_cleaned = df.dropna()\n",
        "print(df_cleaned)"
      ],
      "metadata": {
        "id": "aN9McQI4ftX5",
        "outputId": "db9e934b-1bc7-4842-adf8-f22a72d8b025",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     A     B   C\n",
            "0  1.0   6.0  11\n",
            "4  5.0  10.0  15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will remove all rows that contain at least one missing value. If you want to remove columns with missing values, you can use `df.dropna(axis=1)`.\n",
        "\n",
        "**Step A6: Filling Missing Values**\n",
        "\n",
        "To fill missing values, you can use the `fillna()` function. You can replace NaNs with a specific value or with the mean, median, or any other statistic."
      ],
      "metadata": {
        "id": "QQQytebigKac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled = df.fillna(0)  # Replace NaNs with 0\n",
        "print(df_filled)"
      ],
      "metadata": {
        "id": "rqb_c_rNgZhE",
        "outputId": "17cd9840-731f-4c9e-eddc-f17ad950d64b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     A     B   C\n",
            "0  1.0   6.0  11\n",
            "1  2.0   0.0  12\n",
            "2  0.0   8.0  13\n",
            "3  4.0   0.0  14\n",
            "4  5.0  10.0  15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.mean()\n",
        "# unlike NumPy mean works with NaNs"
      ],
      "metadata": {
        "id": "Tricdf15gv6G",
        "outputId": "a74f23c7-db4a-4bf0-abe1-2e512792eb16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "A     3.0\n",
              "B     8.0\n",
              "C    13.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "df_mean_filled = df.fillna(df.mean())\n",
        "print(df_mean_filled)"
      ],
      "metadata": {
        "id": "hhXDRMiIghyB",
        "outputId": "e222624f-3c97-4ba8-86e0-4b18a761a13f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     A     B   C\n",
            "0  1.0   6.0  11\n",
            "1  2.0   8.0  12\n",
            "2  3.0   8.0  13\n",
            "3  4.0   8.0  14\n",
            "4  5.0  10.0  15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step A7: Interpolation**\n",
        "\n",
        "Pandas provides interpolation methods for filling missing values. For example, to perform linear interpolation, you can use:"
      ],
      "metadata": {
        "id": "FDI7E_7khDQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_interpolated = df.interpolate()\n",
        "print(df_interpolated)"
      ],
      "metadata": {
        "id": "1mtMOU_JTd7i",
        "outputId": "323e3708-0e58-42c1-b3cc-063548e3b230",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     A     B   C\n",
            "0  1.0   6.0  11\n",
            "1  2.0   7.0  12\n",
            "2  3.0   8.0  13\n",
            "3  4.0   9.0  14\n",
            "4  5.0  10.0  15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's it! You've now learned how to deal with missing values in Python using Pandas and NumPy, including identifying, counting, removing, filling, and interpolating missing values. Apply it to your datasets.\n",
        "\n",
        "In more complex scenarios, you might want to use more advanced imputation techniques. For example, you can use scikit-learn's SimpleImputer to fill missing values with the mean, median, or a custom strategy."
      ],
      "metadata": {
        "id": "tPvLIhzFhsYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Common Pitfall:** when to use inplace=True\n",
        "\n",
        "Many Pandas functions can take an argument of `inplace=True`. The difference between in-place and \"normal\" function calls is that in-place modifies the data object directly while \"normal\" functions return a copy (or a view).\n",
        "\n",
        "It's important to use `inplace=True` with care because it modifies the original object, and you cannot easily revert the changes. Make sure you have a backup of your data or a clear understanding of the consequences before using `inplace=True`. Additionally, in some cases, it can be better to create a new DataFrame or Series and assign the modified result to it instead of using `inplace=True`."
      ],
      "metadata": {
        "id": "VtykKIo8wam9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step B1: Create a Sample DataFrame**\n",
        "\n",
        "Let's create a sample DataFrame with a categorical variable that we will encode and decode."
      ],
      "metadata": {
        "id": "slrz5yeyiHyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Category': ['A', 'B', 'A', 'C', 'B', 'C', 'A'],\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Encode the 'Category' column\n",
        "df['Encoded_Category'] = df['Category'].map({'A': 0, 'B': 1, 'C': 2})\n",
        "\n",
        "# Create a valid dictionary for decoding\n",
        "category_dict = {0: 'A', 1: 'B', 2: 'C'}\n",
        "\n",
        "# Decode the 'Encoded_Category' column\n",
        "df['Decoded_Category'] = df['Encoded_Category'].map(category_dict)\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "0rthEJkzvQz-",
        "outputId": "f83e9ec6-d2ca-45ff-d657-52f16d85e41e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Category  Encoded_Category Decoded_Category\n",
            "0        A                 0                A\n",
            "1        B                 1                B\n",
            "2        A                 0                A\n",
            "3        C                 2                C\n",
            "4        B                 1                B\n",
            "5        C                 2                C\n",
            "6        A                 0                A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step B2: One-hot Encoding**\n",
        "\n",
        "To encode categorical variables, you can use one-hot encoding. Pandas provides a convenient method called `pd.get_dummies()` for this purpose."
      ],
      "metadata": {
        "id": "VOqX9sqTib61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Category': ['A', 'B', 'C', 'A', 'B', 'C']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "# Perform one-hot encoding"
      ],
      "metadata": {
        "id": "FZqtNpZsiV9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will convert the categorical variable 'Category' into binary columns for each category.\n",
        "\n",
        "Now, let's say you want to convert the one-hot encoded columns back to the original categorical variable."
      ],
      "metadata": {
        "id": "sSNYsMxkiu7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step B3: Decoding the DataFrame**\n",
        "\n",
        "To decode the DataFrame, use `idxmax(axis=1)` to find the column with the highest value (1) for each row, and then we use `str.replace()` to remove the \"Category_\" prefix from the column names. Finally, create a new 'Decoded_Category' column in the DataFrame with the decoded values."
      ],
      "metadata": {
        "id": "MlyAe4_njEtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Create a decoding function to map the one-hot encoded columns back to categories\n",
        "\n",
        "# Decode the one-hot encoded columns and remove the \"Category_\" prefix\n",
        "\n",
        "# Create a new 'Decoded_Category' column\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "FDWVBDzBygn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore other encoding options...\n",
        "\n",
        "- Frequency (Count) Encoding: This method replaces categories with the frequency (count) of each category in the dataset. It can be useful when the frequency of categories is relevant information.\n",
        "\n",
        "- Target Encoding (Mean Encoding): In target encoding, the categories are replaced with the mean of the target variable for each category. It's often used in classification tasks."
      ],
      "metadata": {
        "id": "CT8yNjYlkMgS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step B4: Frequency (Count) Encoding:**\n",
        "\n",
        "Let's say you have a Data Frame with a categorical column Color, and you want to perform frequency encoding on it:"
      ],
      "metadata": {
        "id": "OZ96-3S9lIeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Color': ['Red', 'Blue', 'Red', 'Green', 'Blue', 'Green', 'Red', 'Red']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the frequency of each category and create a mapping\n",
        "frequency_map = df['Color'].value_counts().to_dict()\n",
        "\n",
        "# Apply frequency encoding to the 'Color' column\n",
        "df['Color_Frequency'] = df['Color'].map(frequency_map)\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "O_n3asPKlgMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, the 'Color_Frequency' column will contain the count (frequency) of each color in the 'Color' column.\n"
      ],
      "metadata": {
        "id": "XMw180B3ltvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step C1: Grouping Data**\n",
        "\n",
        "You can use the `groupby` function to group the data based on a specific column. For example, let's group the data by the 'Category' column:"
      ],
      "metadata": {
        "id": "rjJYDzay0-VQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Category': ['A', 'B', 'A', 'B', 'A', 'A'],\n",
        "    'Value': [10, 20, 15, 25, 12, 18]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "grouped = df.groupby('Category')"
      ],
      "metadata": {
        "id": "99qM2Tv41EKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step C2: Aggregating Data**\n",
        "\n",
        "Once you have grouped the data, you can perform various aggregation operations. Some common aggregation methods include `sum()`, `mean()`, `max()`, `min()`, and `count()`. For instance, to find the sum of 'Value' within each category:"
      ],
      "metadata": {
        "id": "3gLvrq491Z0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "6PEKXhcJ1tGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step C3: Multiple Aggregations**\n",
        "\n",
        "You can perform multiple aggregations at once using the `agg` method. For instance, to find both the sum and mean of 'Value' by category:"
      ],
      "metadata": {
        "id": "2AdSHoJ213tJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "o_bfBWCt2BWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step C4: Resetting the Index**\n",
        "\n",
        "By default, the grouped column becomes the index. Reset the index and keep the results as columns:"
      ],
      "metadata": {
        "id": "RGrGTWez2Mg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make use of .reset_index()\n",
        "agg_result"
      ],
      "metadata": {
        "id": "HZu1l5pL2YVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, practice grouping by multiple columns on a dataset with more columns!"
      ],
      "metadata": {
        "id": "DOT5mato2sKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step D1: Wide vs Long Formats**\n",
        "\n",
        "Let's practice with Halloween data you used for Tableau Practical. We prefered to tranform the file outside the Tableau and we will learn how to do it in Python. Still, it is possible to do that in Tableau by pivoting the table."
      ],
      "metadata": {
        "id": "s1ZNZSjB9xvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O week6_data.zip \"https://drive.google.com/uc?export=download&id=1_cmPeepnFq4EDAvlnsFsFR9pNKiCo-jo\"\n",
        "!unzip week6_data.zip"
      ],
      "metadata": {
        "id": "-3bvhByk-QP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_wide = pd.read_csv('trick_or_treat.csv')\n",
        "df_wide"
      ],
      "metadata": {
        "id": "St3tCZ_3-2jT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step D2: Converting from Wide to Long Format**\n",
        "\n",
        "To convert from wide to long format, you can use the `melt` function. You need to specify which columns to keep as identifier variables (e.g., 'Year') and which columns to melt into a new variable. In this example, we will melt the timeslot columns into a 'Time' column:"
      ],
      "metadata": {
        "id": "R731JWdu_lsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_long = pd.melt(df_wide, id_vars=['Year'], var_name='Time', value_name='Counts')\n",
        "df_long"
      ],
      "metadata": {
        "id": "1pjva7C1ACz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting DataFrame (**`df_long`**) will be in long format, where each row represents a unique combination of 'Year' and 'Time'.\n",
        "\n",
        "**Step D3: Converting from Long to Wide Format**\n",
        "\n",
        "To convert data back from long to wide format, you can use the `pivot` function. This requires specifying which columns to use as the index, columns, and values."
      ],
      "metadata": {
        "id": "VpWbZO1CAY1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_wide_back = df_long.pivot(index='Year', columns='Time', values='Counts').reset_index()\n",
        "df_wide_back"
      ],
      "metadata": {
        "id": "kDdv8cEeAvbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sorting rows and columns?\n"
      ],
      "metadata": {
        "id": "TRxhH_cTCyCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `pivot` function reshapes the data back into wide format using 'Year' as the index, 'Time' as the columns, and 'Counts' as the values. The `reset_index()` function is used to restore 'Year' as a column."
      ],
      "metadata": {
        "id": "nZ_F9mhbAyOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Remarks: Input / Output**\n",
        "\n",
        "For example, `pd.read_csv` will read in a CSV file and create a `DataFrame`.\n",
        "\n",
        "Getting data out again can also be done in several ways: `df.to_numpy()` to create numpy arrays or `df.to_csv(\"filename.csv\")` to write out to a CSV file."
      ],
      "metadata": {
        "id": "JOkg5xFoq_pX"
      }
    }
  ]
}